{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_type <- \"classification\" #classification  #regression\n",
    "datasets_path   <- paste0('E:/Mestrado_ranker/datasets_scores/',prediction_type,'/')\n",
    "scores_path     <- paste0('E:/Mestrado_ranker/R_output_analisys/data_scores/',prediction_type,'/')\n",
    "plots_path      <- paste0('E:/Mestrado_ranker/R_output_analisys/plots/',prediction_type,'/')\n",
    "friedman_path   <- paste0('E:/Mestrado_ranker/R_output_analisys/friedman/',prediction_type,'/')\n",
    "\n",
    "dataset_names <- list.files(path=datasets_path, full.names = FALSE, pattern = \"\\\\_scores$\")\n",
    "dataset_names <- gsub(\"_scores\", \"\", dataset_names)\n",
    "\n",
    "noisy_features <- list(\"001\", \"002\", \"004\", \"008\", \"016\", \"032\", \"064\",\"128\",\"256\",\"512\",\"1024\")\n",
    "scoring_measures <- list(\n",
    "  'binary_rs1',\n",
    "  'binary_rs2',\n",
    "  'binary_rs3',\n",
    "  'geometricMean_rs1',\n",
    "  'geometricMean_rs2',\n",
    "  'geometricMean_rs3',\n",
    "  'gini_rs1',\n",
    "  'gini_rs2',\n",
    "  'gini_rs3',\n",
    "  'oobScore_rs1',\n",
    "  'oobScore_rs2',\n",
    "  'oobScore_rs3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRIAR FUNCAO PARA TRANSFORMACAO DOS DADOS DE MYDATA.AVERAGE PARA VEC_NEWFORMAT\n",
    "cantao_dataset_restructure <- function(mydata.average){\n",
    "  #creating a new empty vector and transforming it to a data frame (para poder usar o rbind)\n",
    "  newformat <- as.data.frame(newformat <- c())\n",
    "  \n",
    "  #transforming the column-values to line-values for each centrality\n",
    "  #and insert it to the new data frame (as new row)\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"g\",   centrality=\"katz\",  centrality_or_forest=\"c\", value=mydata.average$averageGKatz))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"g\",   centrality=\"eigen\", centrality_or_forest=\"c\", value=mydata.average$averageGEigen))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"g\",   centrality=\"str\",   centrality_or_forest=\"c\", value=mydata.average$averageGStr))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"in\",  centrality=\"katz\",  centrality_or_forest=\"c\", value=mydata.average$averageGDirInKatz))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"in\",  centrality=\"eigen\", centrality_or_forest=\"c\", value=mydata.average$averageGDirInEigen))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"in\",  centrality=\"str\",   centrality_or_forest=\"c\", value=mydata.average$averageGDirInStr))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"out\", centrality=\"katz\",  centrality_or_forest=\"c\", value=mydata.average$averageGDirOutKatz))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"out\", centrality=\"eigen\", centrality_or_forest=\"c\", value=mydata.average$averageGDirOutEigen))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"out\", centrality=\"str\",   centrality_or_forest=\"c\", value=mydata.average$averageGDirOutStr))\n",
    "  newformat <- rbind(newformat, data.frame(orientation=\"rf\", centrality=\"rf\", centrality_or_forest=\"f\", value=mydata.average$averageForestRanking))\n",
    "  #INSERIR COLUNA MEASURE_NAME? ou substituir a coluna atual centrality por measure_name?\n",
    "  \n",
    "  #inserting the ramaining columns to the new data frame (no need for transformation here)\n",
    "  newformat <- cbind(newformat, dataset=mydata.average$dataset, noise=mydata.average$noisePercentual, R=mydata.average$noisyFeatures)\n",
    "  return(newformat)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (scoring_measure in scoring_measures){\n",
    "  mydata.average <- NULL\n",
    "  for (dataset_name in dataset_names){\n",
    "    for (kfold in seq(10)){\n",
    "      for (noise in noisy_features){\n",
    "        filePathAverage <- paste0(datasets_path,dataset_name,\"_scores/\",sprintf(\"%03d\", kfold),\"/\",noise,\"/score/average_\",dataset_name,\"_\",scoring_measure,\".txt\")\n",
    "        newdataaverage  <- read.table(filePathAverage, header=TRUE, sep=\"\\t\")\n",
    "          \n",
    "        #creating a new column and filling with the dataset name\n",
    "        newdataaverage$dataset <- dataset_name\n",
    "\n",
    "        #creating a new column and filling with the amount of noise used\n",
    "        newdataaverage$noisyFeatures <- noise\n",
    "\n",
    "        #binding each file to the single file of results\n",
    "        mydata.average   <- rbind(mydata.average, newdataaverage)\n",
    "#        mydata.std   <- rbind(mydata.std, newdatastd)\n",
    "        #printing the paths used to double-check\n",
    "        #print(filePathAverage)\n",
    "      }\n",
    "    }\n",
    "    cat(scoring_measure, ': ', dataset_name, 'OK\\n')\n",
    "  }\n",
    "  #MUDAR NOME DATASET NOVO \"vec_newformat\n",
    "  vec_newformat  <- NULL\n",
    "  vec_newformat  <- cantao_dataset_restructure(mydata.average)\n",
    "  mydata.average <- NULL\n",
    "  #converter coluna R de factor para numeric\n",
    "  vec_newformat$R <- as.numeric(levels(vec_newformat$R))[vec_newformat$R]\n",
    "  write.csv(vec_newformat, file=paste0(scores_path,'scores_',scoring_measure,'.csv'), row.names = FALSE)\n",
    "  vec_newformat  <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION to summarize dataset and plot graph\n",
    "#### based on 4 given information: dataset, x_data, y_data and group_by_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantao_plot <- function(dataset, x_data, y_data, group_by_data, group_by_label, measure='mean', visu='points'){\n",
    "    require(ggplot2)\n",
    "    require(gridExtra)\n",
    "    if(visu == 'points'){\n",
    "        #require loads the package only if its not already loaded\n",
    "        require(FSA)\n",
    "        Sum = Summarize(y_data ~ x_data + group_by_data, data=dataset)\n",
    "        #standard error\n",
    "        #Sum$se = Sum$sd / sqrt(Sum$n)\n",
    "        require(dplyr)\n",
    "        Sum <- Sum %>%\n",
    "        group_by(x_data) %>%\n",
    "        mutate(width = 0.5 * as.numeric(x_data))\n",
    "      if(measure == 'mean'){\n",
    "          y_data  = Sum$mean\n",
    "          err_min = Sum$mean - Sum$sd\n",
    "          err_max = Sum$mean + Sum$sd\n",
    "      }else if(measure == 'median'){# == 'median'\n",
    "          y_data  = Sum$median\n",
    "          err_min = Sum$median - (Sum$Q3 - Sum$Q1)\n",
    "          err_max = Sum$median + (Sum$Q3 - Sum$Q1)\n",
    "      }else{\n",
    "          print(\"please set the measure variable to 'mean' or 'median'\")\n",
    "      }\n",
    "      pd = position_dodge(0.8) #0.5   ### How much to jitter the points on the plot\n",
    "      p <- ggplot(Sum,                ### The data frame to use. \n",
    "                  #aes(x     = factor(x_data, levels = c(\"1\",\"2\",\"4\",\"8\",\"16\",\"32\",\"64\",\"128\",\"256\",\"512\",\"1024\")), #remover log2() e usar string no eixo X\n",
    "                  aes(x     = factor(x_data, levels = unique(x_data)),\n",
    "                      y     = y_data,\n",
    "                      color = group_by_data,\n",
    "                      group = group_by_data)) +\n",
    "           #legend to the group_by variable\n",
    "           scale_color_discrete(name=group_by_label) +\n",
    "           scale_shape_discrete(name=group_by_label) + \n",
    "           geom_point(aes(shape=group_by_data),  size  = 3.0, position = pd) +\n",
    "           geom_errorbar(aes(ymin  = err_min,  #se\n",
    "                             ymax  = err_max), #se\n",
    "                         #linetype=group_by_data),\n",
    "                         width = 1.0, #30.5\n",
    "                         size  = 0.5, \n",
    "                         position = pd) +\n",
    "           #geom_line(aes(linetype=group_by_data),  size  = 2.0, position = pd) + \n",
    "           geom_line(size  = 0.7, position = pd)\n",
    "    }else if(visu == 'boxplot'){\n",
    "        err_min = 0\n",
    "        err_max = 1\n",
    "        p <- ggplot(dataset,                \n",
    "                      aes(x    = factor(x_data),                  #x_data\n",
    "                          y    = value,              #y_data\n",
    "                          fill = group_by_data)) +      #group_by_data\n",
    "            geom_boxplot() +\n",
    "            labs(fill=group_by_label)\n",
    "    }else{\n",
    "        print(\"please set the visu variable to 'points' or 'boxplot'\")\n",
    "    }\n",
    "    p <- p + \n",
    "    theme_bw() + #background of the plotting area \n",
    "    theme(plot.title = element_text(hjust = 0.5)) +\n",
    "    xlab(expression(paste(\"Total Features \", (x * rho + rho)))) + #(2^x * rho + rho)\n",
    "    ylab(\"Mean Ranking Score\") +\n",
    "    ggtitle(label = dataset$title)+\n",
    "    ylim(\n",
    "       min(0, err_min), \n",
    "       max(1, err_max)\n",
    "    )\n",
    "    return (p)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loads structured dataset averages for each weight and ranking score (rs) and plot averages graphs #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time <- Sys.time()\n",
    "\n",
    "measure = 'mean' # 'median'  'mean'\n",
    "visu    = 'points' #'points' 'boxplot'\n",
    "\n",
    "files <- list.files(path=scores_path, full.names = TRUE, pattern = \"\\\\.csv$\")\n",
    "plot_sufix <- '_85datasets_10folds.pdf'\n",
    "\n",
    "for (file in files){\n",
    "  vec_newformat <- read.table(file, header=TRUE, sep=\",\")\n",
    "  #removes the first and last part of the string to keep only scoring measure name\n",
    "  sub_partial <- sub(\".*scores_\", \"\", file)\n",
    "  scoring_measure <- sub(\"\\\\..*\", \"\", sub_partial)\n",
    "  \n",
    "  output_plot_dir = paste0(plots_path,scoring_measure,'/')\n",
    "  if (!dir.exists(output_plot_dir)){\n",
    "    dir.create(file.path(output_plot_dir), recursive=TRUE)\n",
    "  }\n",
    "  # NDC --- transposed of DNC\n",
    "  #saving all 12 subsets for NDC in ndc[[]] list\n",
    "  ndc <- list() #Noise Dataset Centrality (NDC)\n",
    "  i=1\n",
    "  for(noi in c(5,10,20,40)){ #for each noise percentage on examples\n",
    "    for(ori in c(\"g\", \"in\", \"out\")){ #for each orientation in graph\n",
    "      ndc[[i]] <- subset(vec_newformat, noise == noi & (orientation == ori | centrality_or_forest == \"f\"))\n",
    "      ndc[[i]]$title <- paste0('Noise Rate: ', noi,'%;', ' Orientation: ', ori)\n",
    "      i=i+1\n",
    "    }\n",
    "  }\n",
    "  #plotting each of the subsets for NDC\n",
    "  p <- list()\n",
    "  i = 1\n",
    "  for (data_subset in ndc){ \n",
    "    p[[i]] <- cantao_plot(dataset = data_subset,\n",
    "                          #x_data = log2(data_subset$R),\n",
    "                          x_data = as.factor(data_subset$R),\n",
    "                          y_data = data_subset$value,\n",
    "                          group_by_data = data_subset$centrality,\n",
    "                          group_by_label = 'Centrality',\n",
    "                          measure,\n",
    "                          visu)\n",
    "    i=i+1\n",
    "  }\n",
    "  #showing plot\n",
    "  #grid.arrange(grobs = p, ncol=3)\n",
    "  #saving plot\n",
    "  g <- arrangeGrob(grobs = p, ncol=3)\n",
    "  ggsave(file=paste0(output_plot_dir,'NDC_',scoring_measure, plot_sufix), g,width = 13, height = 13)\n",
    "  \n",
    "  # NCD --- transposed of CND\n",
    "  ncd <- list()\n",
    "  i=1\n",
    "  for (noi in c(5,10,20,40)){\n",
    "    for(cent in c(\"katz\", \"eigen\", \"str\")){\n",
    "      ncd[[i]] <- subset(vec_newformat, noise == noi & (centrality == cent | centrality_or_forest == \"f\"))\n",
    "      ncd[[i]]$title <- paste0('Noise: ', noi,'%;', ' Centrality: ', cent)\n",
    "      i=i+1\n",
    "    }\n",
    "  }\n",
    "  #plotting each of the subsets for NCD\n",
    "  p <- list()\n",
    "  i = 1\n",
    "  for (data_subset in ncd){ #\n",
    "    p[[i]] <- cantao_plot(dataset = data_subset,\n",
    "                          x_data = data_subset$R,\n",
    "                          y_data = data_subset$value,\n",
    "                          group_by_data = data_subset$orientation,\n",
    "                          group_by_label = 'Orientation',\n",
    "                          measure,\n",
    "                          visu)\n",
    "    i=i+1\n",
    "  }\n",
    "  #grid.arrange(grobs = p, ncol=3)\n",
    "  g <- arrangeGrob(grobs = p, ncol=3) \n",
    "  ggsave(file=paste0(output_plot_dir,'NCD_',scoring_measure,plot_sufix), g,width = 13, height = 13)\n",
    "  \n",
    "  \n",
    "  # DCN --- transposed of CDN \n",
    "  dcn <- list()\n",
    "  i=1\n",
    "  for(ori in c(\"g\", \"in\", \"out\", \"rf\")){\n",
    "    for(cent in c(\"katz\", \"eigen\", \"str\")){\n",
    "      dcn[[i]] <- subset(vec_newformat, orientation == ori & (centrality == cent | centrality_or_forest == \"f\"))\n",
    "      #dcn[[i]]$noise <- as.factor(dcn[[i]]$noise)\n",
    "      dcn[[i]]$title <- paste0('Orientation: ', ori,'; Centrality: ', cent)\n",
    "      i=i+1\n",
    "    }\n",
    "  }\n",
    "  #plotting each of the subsets for DCN\n",
    "  p <- list()\n",
    "  i = 1\n",
    "  for (data_subset in dcn){ #\n",
    "    p[[i]] <- cantao_plot(dataset = data_subset,\n",
    "                          x_data = data_subset$R,\n",
    "                          y_data = data_subset$value,\n",
    "                          group_by_data = as.character(data_subset$noise),\n",
    "                          group_by_label = 'Noise',\n",
    "                          measure,\n",
    "                          visu)\n",
    "    i=i+1\n",
    "  }\n",
    "  #grid.arrange(grobs = p, ncol=3)\n",
    "  g <- arrangeGrob(grobs = p, ncol=3)\n",
    "  ggsave(file=paste0(output_plot_dir,'DCN_',scoring_measure,plot_sufix), g, width = 13, height = 13)\n",
    "}\n",
    "\n",
    "end_time <- Sys.time()\n",
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads structured dataset scores for each weight and ranking score (rs) and saves friedman table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files <- list.files(path=scores_path, full.names = TRUE, pattern = \"\\\\.csv$\")\n",
    "for (file in files){\n",
    "  vec_newformat <- read.table(file, header=TRUE, sep=\",\")\n",
    "  #removes the first and last part of the string to keep only scoring measure name\n",
    "  sub_partial <- sub(\".*scores_\", \"\", file)\n",
    "  scoring_measure <- sub(\"\\\\..*\", \"\", sub_partial)\n",
    "  \n",
    "  output_friedman_dir = paste0(friedman_path,scoring_measure,'/')\n",
    "  if (!dir.exists(output_friedman_dir)){\n",
    "    dir.create(file.path(output_friedman_dir), recursive=TRUE)\n",
    "  }\n",
    "  directions   <- unique(vec_newformat$orientation)   #list(\"g\", \"in\", \"out\", \"rf\")\n",
    "  directions   <- setdiff(directions, \"rf\") # getting all centralities that are not \"rf\"\n",
    "  centralities <- unique(vec_newformat$centrality) #list(\"katz\", \"eigen\", \"str\", \"rf\")\n",
    "  noises       <- unique(vec_newformat$noise) #list(5,10,20,40)\n",
    "  rs           <- unique(vec_newformat$R) #1,2,4,8,16..1024\n",
    "  #-----------------------------------------------------------------------------\n",
    "  #--------------------------------Friedman-DCN----------------------------------\n",
    "  for (dir in directions){  #D .. 3 files\n",
    "    #11linhas = R... 13 colunas = katz_5, katz_10, katz_20, katz_40, eigen_5...\n",
    "    vec_metric <- matrix(, nrow = 11, ncol = 16)\n",
    "    #personalized column names using 'dir_cent_noi'\n",
    "    dataset_col_names <- list()\n",
    "    \n",
    "    i=0\n",
    "    for (cent in centralities){ #C\n",
    "      #cat(\"\\ncent: \", cent)\n",
    "      if (cent == \"rf\") #para cent=='rf' nao utiliza as direcoes 'g', 'in' e 'out'\n",
    "        a <- subset(vec_newformat, centrality=='rf') \n",
    "      else\n",
    "        a <- subset(vec_newformat, orientation==dir & centrality==cent)\n",
    "      for (noi in noises){ #N\n",
    "        i=i+1\n",
    "        dataset_col_names[length(dataset_col_names)+1] <- paste0(dir, \"_\", cent, \"_\", noi)\n",
    "        #cat(\"\\nnoi: \", noi)\n",
    "        #cat(paste0(dir, \"_\", cent, \"_\", noi))\n",
    "        b<-subset(a, noise==noi)\n",
    "        \n",
    "        j=0\n",
    "        for (r in rs){\n",
    "          #cat(\"\\nr: \" ,r)\n",
    "          c<-subset(b, R==r)\n",
    "          j=j+1\n",
    "          vec_metric[j,i] <- mean(c$value)\n",
    "          #cat(\"value: \", vec_metric[j,i])\n",
    "          #cat(\"i: \", i, \"j: \", j)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    #create a dataframe from the matrix and rename the columns\n",
    "    metrics_mean <- as.data.frame(vec_metric)\n",
    "    colnames(metrics_mean) <- dataset_col_names\n",
    "    #saving table to a CSV file\n",
    "    write.csv(metrics_mean,file=paste0(output_friedman_dir,'DCN_',dir,'_',scoring_measure,'.csv'),row.names=FALSE)\n",
    "    cat(scoring_measure,': DCN - OK\\n')\n",
    "  }\n",
    "  #-----------------------------------------------------------------------------\n",
    "  #-------------------------------Friedman-NDC----------------------------------\n",
    "  centralities_without_rf <- setdiff(centralities, \"rf\")\n",
    "  for (noi in noises){ #N ...4 files\n",
    "    #creating empty matrix to store the mean results\n",
    "    vec_metric <- matrix(, nrow = 11, ncol = 10) #files: noises(4) \n",
    "    dataset_col_names <- list()                  #columns: orientation(3)*centralities(3) + rf(1) \n",
    "    i=0\n",
    "    for(dir in directions){ #D\n",
    "      #cat(\"\\ndir: \", dir)\n",
    "      a <- subset(vec_newformat, noise == noi & orientation==dir) #| noise == noi & orientation=='rf')\n",
    "      for(cent in centralities_without_rf){ #C\n",
    "        i=i+1\n",
    "        dataset_col_names[length(dataset_col_names)+1] <- paste0(noi, \"_\", dir, \"_\", cent)\n",
    "        b <- subset(a, centrality==cent)\n",
    "        j=0\n",
    "        for (r in rs){#for each slice of 01R, 02R...\n",
    "          #cat(\"\\nr: \" ,r)\n",
    "          c<-subset(b, R==r)\n",
    "          j=j+1\n",
    "          vec_metric[j,i] <- mean(c$value)\n",
    "          #cat(\"value: \", vec_metric[j,i])\n",
    "          #cat(\"i: \", i, \"j: \", j)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    #working with column RF\n",
    "    a <- subset(vec_newformat, noise == noi & orientation=='rf')\n",
    "    i=i+1\n",
    "    dataset_col_names[length(dataset_col_names)+1] <- paste0(noi, \"_rf\")\n",
    "    b <- subset(a, centrality=='rf')\n",
    "    j=0\n",
    "    for (r in rs){#for each slice of 01R, 02R...\n",
    "      #cat(\"\\nr: \" ,r)\n",
    "      c<-subset(b, R==r)\n",
    "      j=j+1\n",
    "      vec_metric[j,i] <- mean(c$value)\n",
    "    }\n",
    "    #create a dataframe from the matrix and rename the columns\n",
    "    metrics_mean <- as.data.frame(vec_metric)\n",
    "    colnames(metrics_mean) <- dataset_col_names\n",
    "    #saving table to a CSV file\n",
    "    write.csv(metrics_mean,file=paste0(output_friedman_dir,'NDC_',noi,'_',scoring_measure,'.csv'),row.names=FALSE)\n",
    "    cat(scoring_measure,': NDC - OK\\n')\n",
    "  }\n",
    "  #-----------------------------------------------------------------------------\n",
    "  #-------------------------------Friedman-DNC----------------------------------\n",
    "  for (dir in directions){  #D .. 3 files\n",
    "    #11linhas = R... 13 colunas = katz_5, katz_10, katz_20, katz_40, eigen_5...\n",
    "    vec_metric <- matrix(, nrow = 11, ncol = 16)\n",
    "    #personalized column names using 'dir_cent_noi'\n",
    "    dataset_col_names <- list()\n",
    "    i=0\n",
    "    for (noi in noises){ #N\n",
    "      #cat(\"\\nnoi: \", noi)\n",
    "      a <- subset(vec_newformat, orientation==dir & noise==noi | orientation=='rf' & noise==noi)\n",
    "      for (cent in centralities){ #C\n",
    "        i=i+1\n",
    "        dataset_col_names[length(dataset_col_names)+1] <- paste0(dir, \"_\", noi, \"_\", cent)\n",
    "        #cat(\"\\ncent: \", cent)\n",
    "        #cat(paste0(dir, \"_\", noi, \"_\", cent))\n",
    "        if (cent == \"rf\") #para cent=='rf' nao utiliza as direcoes 'g', 'in' e 'out'\n",
    "          b<-subset(a, centrality=='rf')\n",
    "        else\n",
    "          b<-subset(a, centrality==cent)\n",
    "        \n",
    "        j=0\n",
    "        for (r in rs){\n",
    "          #cat(\"\\nr: \" ,r)\n",
    "          c<-subset(b, R==r)\n",
    "          j=j+1\n",
    "          vec_metric[j,i] <- mean(c$value)\n",
    "          #cat(\"value: \", vec_metric[j,i])\n",
    "          #cat(\"i: \", i, \"j: \", j)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    #create a dataframe from the matrix and rename the columns\n",
    "    metrics_mean <- as.data.frame(vec_metric)\n",
    "    colnames(metrics_mean) <- dataset_col_names\n",
    "    #saving table to a CSV file\n",
    "    write.csv(metrics_mean,file=paste0(output_friedman_dir,'DNC_',dir,'_',scoring_measure,'.csv'),row.names=FALSE)\n",
    "    cat(scoring_measure,': DNC - OK\\n')\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_type <- \"regression\" #classification\n",
    "scores_path     <- paste0('E:/Mestrado_ranker/R_output_analisys/data_scores/',prediction_type,'/')\n",
    "files <- list.files(path=scores_path, full.names = TRUE, pattern = \"\\\\.csv$\")\n",
    "\n",
    "for (file in files[1]){\n",
    "  vec_newformat <- read.table(file, header=TRUE, sep=\",\")\n",
    "  # NDC --- transposed of DNC\n",
    "  #saving all 12 subsets for NDC in ndc[[]] list\n",
    "  ndc <- list() #Noise Dataset Centrality (NDC)\n",
    "  i=1\n",
    "  for(noi in c(5,10,20,40)){ #for each noise percentage on examples\n",
    "    for(ori in c(\"g\", \"in\", \"out\")){ #for each orientation in graph\n",
    "      ndc[[i]] <- subset(vec_newformat, noise == noi & (orientation == ori | centrality_or_forest == \"f\"))\n",
    "      ndc[[i]]$title <- paste0('Noise Rate: ', noi,'%;', ' Orientation: ', ori)\n",
    "      i=i+1\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "require(ggplot2)\n",
    "require(gridExtra)\n",
    "\n",
    "p <- list()\n",
    "i <- 1\n",
    "for (data_subset in ndc){\n",
    "    dataset <- data_subset\n",
    "    x_data <- as.factor(data_subset$R)\n",
    "    y_data <- data_subset$value\n",
    "    group_by_data <- data_subset$centrality\n",
    "    group_by_label <- 'Centrality'\n",
    "    \n",
    "    p[[i]] <- ggplot(dataset,                \n",
    "                      aes(x    = as.factor(x_data),                  #x_data\n",
    "                          y    = value,              #y_data\n",
    "                          fill = group_by_data)) +      #group_by_data\n",
    "                    geom_boxplot()+ \n",
    "                    labs(fill=group_by_label)\n",
    "              \n",
    "    i=i+1\n",
    "}           \n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
